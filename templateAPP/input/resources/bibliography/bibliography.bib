
@misc{oxford_english_dictionary_disinformation_2023,
	title = {disinformation, n.},
	url = {https://doi.org/10.1093/OED/7455799853},
	publisher = {Oxford University Press},
	author = {{Oxford English Dictionary}},
	month = jul,
	year = {2023},
}

@misc{oxford_english_dictionary_misinformation_2024,
	title = {misinformation, n.},
	url = {https://doi.org/10.1093/OED/6889116469},
	publisher = {Oxford University Press},
	author = {{Oxford English Dictionary}},
	month = mar,
	year = {2024},
}

@misc{noauthor_digital_2024,
	title = {Digital 2024: {Global} {Overview} {Report}},
	shorttitle = {Digital 2024},
	url = {https://datareportal.com/reports/digital-2024-global-overview-report},
	abstract = {Everything you need to know about digital and social media use around the world in 2024. 560+ pages of data, trends, and insights - all free.},
	language = {en-GB},
	urldate = {2024-06-17},
	journal = {DataReportal – Global Digital Insights},
	month = jan,
	year = {2024},
	file = {Snapshot:files/7/digital-2024-global-overview-report.html:text/html},
}

@article{allcott_social_2017,
	title = {Social {Media} and {Fake} {News} in the 2016 {Election}},
	volume = {31},
	issn = {0895-3309},
	url = {https://www.aeaweb.org/articles?id=10.1257%2Fjep.31.2.211&fbclid=IwAR04My3},
	doi = {10.1257/jep.31.2.211},
	abstract = {Following the 2016 US presidential election, many have expressed concern about the effects of false stories ("fake news"), circulated largely through social media. We discuss the economics of fake news and present new data on its consumption prior to the election. Drawing on web browsing data, archives of fact-checking websites, and results from a new online survey, we find: 1) social media was an important but not dominant source of election news, with 14 percent of Americans calling social media their "most important" source; 2) of the known false news stories that appeared in the three months before the election, those favoring Trump were shared a total of 30 million times on Facebook, while those favoring Clinton were shared 8 million times; 3) the average American adult saw on the order of one or perhaps several fake news stories in the months around the election, with just over half of those who recalled seeing them believing them; and 4) people are much more likely to believe stories that favor their preferred candidate, especially if they have ideologically segregated social media networks.},
	language = {en},
	number = {2},
	urldate = {2024-06-21},
	journal = {Journal of Economic Perspectives},
	author = {Allcott, Hunt and Gentzkow, Matthew},
	month = may,
	year = {2017},
	keywords = {Economic Anthropology, Language, Media, Economic Sociology, Political Processes: Rent-Seeking, Lobbying, Elections, Legislatures, and Voting Behavior, Entertainment, Social and Economic Stratification},
	pages = {211--236},
	file = {Texto completo:files/9/Allcott y Gentzkow - 2017 - Social Media and Fake News in the 2016 Election.pdf:application/pdf},
}

@article{van_der_linden_inoculating_2020,
	title = {Inoculating {Against} {Fake} {News} {About} {COVID}-19},
	volume = {11},
	issn = {1664-1078},
	url = {https://www.frontiersin.org/journals/psychology/articles/10.3389/fpsyg.2020.566790/full},
	doi = {10.3389/fpsyg.2020.566790},
	abstract = {{\textless}p{\textgreater}The outbreak of the SARS-CoV-2 novel coronavirus (COVID-19) has been accompanied by a large amount of misleading and false information about the virus, especially on social media. In this article, we explore the coronavirus “infodemic” and how behavioral scientists may seek to address this problem. We detail the scope of the problem and discuss the negative influence that COVID-19 misinformation can have on the widespread adoption of health protective behaviors in the population. In response, we explore how insights from the behavioral sciences can be leveraged to manage an effective societal response to curb the spread of misinformation about the virus. In particular, we discuss the theory of psychological inoculation (or {\textless}italic{\textgreater}prebunking{\textless}/italic{\textgreater}) as an efficient vehicle for conferring large-scale psychological resistance against fake news.{\textless}/p{\textgreater}},
	language = {English},
	urldate = {2024-06-21},
	journal = {Frontiers in Psychology},
	author = {van der Linden, Sander and Roozenbeek, Jon and Compton, Josh},
	month = oct,
	year = {2020},
	note = {Publisher: Frontiers},
	keywords = {COVID- 19, fake news, infodemic, Inoculation, misinformation},
	file = {Texto completo:files/11/van der Linden et al. - 2020 - Inoculating Against Fake News About COVID-19.pdf:application/pdf},
}

@misc{noauthor_definition_2024,
	title = {Definition of {MISINFORMATION}},
	url = {https://www.merriam-webster.com/dictionary/misinformation},
	abstract = {incorrect or misleading information… See the full definition},
	language = {en},
	urldate = {2024-06-21},
	month = jun,
	year = {2024},
}

@misc{noauthor_definition_2024-1,
	title = {Definition of {DISINFORMATION}},
	url = {https://www.merriam-webster.com/dictionary/disinformation},
	abstract = {false information deliberately and often covertly spread (as by the planting of rumors) in order to influence public opinion or obscure the truth… See the full definition},
	language = {en},
	urldate = {2024-06-21},
	month = jun,
	year = {2024},
}

@article{aimeur_fake_2023,
	title = {Fake news, disinformation and misinformation in social media: a review},
	volume = {13},
	issn = {1869-5450, 1869-5469},
	shorttitle = {Fake news, disinformation and misinformation in social media},
	url = {https://www.webofscience.com/wos/woscc/full-record/WOS:000932145900001},
	doi = {10.1007/s13278-023-01028-5},
	abstract = {Online social networks (OSNs) are rapidly growing and have become a huge source of all kinds of global and local news for millions of users. However, OSNs are a double-edged sword. Although the great advantages they offer such as unlimited easy communication and instant news and information, they can also have many disadvantages and issues. One of their major challenging issues is the spread of fake news. Fake news identification is still a complex unresolved issue. Furthermore, fake news detection on OSNs presents unique characteristics and challenges that make finding a solution anything but trivial. On the other hand, artificial intelligence (AI) approaches are still incapable of overcoming this challenging problem. To make matters worse, AI techniques such as machine learning and deep learning are leveraged to deceive people by creating and disseminating fake content. Consequently, automatic fake news detection remains a huge challenge, primarily because the content is designed in a way to closely resemble the truth, and it is often hard to determine its veracity by AI alone without additional information from third parties. This work aims to provide a comprehensive and systematic review of fake news research as well as a fundamental review of existing approaches used to detect and prevent fake news from spreading via OSNs. We present the research problem and the existing challenges, discuss the state of the art in existing approaches for fake news detection, and point out the future research directions in tackling the challenges.},
	language = {English},
	number = {1},
	urldate = {2024-06-21},
	journal = {SOCIAL NETWORK ANALYSIS AND MINING},
	author = {Aimeur, Esma and Amri, Sabrine and Brassard, Gilles},
	month = feb,
	year = {2023},
	note = {Num Pages: 36
Place: Vienna
Publisher: Springer Wien
Web of Science ID: WOS:000932145900001},
	keywords = {BLOCKCHAIN, CHECK, Disinformation, Fake news, FALSE, Information disorder, Misinformation, Online deception, Online social networks, ORIGINS, SPREAD, STORIES},
	pages = {30},
	file = {Texto completo:files/15/Aimeur et al. - 2023 - Fake news, disinformation and misinformation in so.pdf:application/pdf},
}

@article{s_too_nodate,
	title = {Too {Much} {Information}, {Too} {Little} {Time}: {How} the {Brain} {Separates} {Important} from {Unimportant} {Things} in {Our} {Fast}-{Paced} {Media} {World}. {Front}. {Young} {Minds}.},
	doi = {10.3389/frym.2017.00023},
	author = {S, Heim and A, Keil},
}

@article{mckay_disinformation_2021,
	title = {Disinformation as a {Threat} to {Deliberative} {Democracy}},
	volume = {74},
	issn = {1065-9129},
	url = {https://doi.org/10.1177/1065912920938143},
	doi = {10.1177/1065912920938143},
	abstract = {It is frequently claimed that online disinformation threatens democracy, and that disinformation is more prevalent or harmful because social media platforms have disrupted our communication systems. These intuitions have not been fully developed in democratic theory. This article builds on systemic approaches to deliberative democracy to characterize key vulnerabilities of social media platforms that disinformation actors exploit, and to clarify potential anti-deliberative effects of disinformation. The disinformation campaigns mounted by Russian agents around the United States’ 2016 election illustrate the use of anti-deliberative tactics, including corrosive falsehoods, moral denigration, and unjustified inclusion. We further propose that these tactics might contribute to the system-level anti-deliberative properties of epistemic cynicism, techno-affective polarization, and pervasive inauthenticity. These harms undermine a polity’s capacity to engage in communication characterized by the use of facts and logic, moral respect, and democratic inclusion. Clarifying which democratic goods are at risk from disinformation, and how they are put at risk, can help identify policies that go beyond targeting the architects of disinformation campaigns to address structural vulnerabilities in deliberative systems.},
	language = {en},
	number = {3},
	urldate = {2024-11-23},
	journal = {Political Research Quarterly},
	author = {McKay, Spencer and Tenove, Chris},
	month = sep,
	year = {2021},
	note = {Publisher: SAGE Publications Inc},
	pages = {703--717},
	file = {SAGE PDF Full Text:files/20/McKay y Tenove - 2021 - Disinformation as a Threat to Deliberative Democra.pdf:application/pdf},
}

@misc{noauthor_misinformation_nodate,
	title = {Misinformation is eroding the public’s confidence in democracy},
	url = {https://www.brookings.edu/articles/misinformation-is-eroding-the-publics-confidence-in-democracy/},
	urldate = {2024-11-23},
	file = {Misinformation is eroding the public’s confidence in democracy:files/22/misinformation-is-eroding-the-publics-confidence-in-democracy.html:text/html},
}

@misc{noauthor_infodemic_nodate,
	title = {Infodemic},
	url = {https://www.who.int/health-topics/infodemic},
	abstract = {abundance of information – some accurate and some not – that occurs during an epidemic. It can lead to confusion and ultimately mistrust in governments and public health response.},
	language = {en},
	urldate = {2024-11-23},
	file = {Snapshot:files/26/infodemic.html:text/html},
}

@article{michaels_gamestop_2021,
	chapter = {Markets},
	title = {{GameStop} {Stock} {Surge} {Tests} {Scope} of {SEC}’s {Manipulation} {Rules}},
	issn = {0099-9660},
	url = {https://www.wsj.com/articles/gamestop-surge-tests-scope-of-secs-manipulation-rules-11611838175},
	abstract = {The frenzy for GameStop shares has played out on public websites where investors exhort others to buy shares and options, which could make it easier for regulators to levy claims of manipulation.},
	language = {en-US},
	urldate = {2024-11-23},
	journal = {Wall Street Journal},
	author = {Michaels, Dave and Osipovich, Alexander},
	month = jan,
	year = {2021},
	keywords = {acquisitions, Acquisitions/Mergers/Shareholdings, Alternative Investments, AMC, AMC Entertainment Holdings, BBBY, Bed Bath \& Beyond, business, Business/Consumer Services, C\&E Executive News Filter, C\&E Industry News Filter, consumer services, Content Types, corporate, Corporate Actions, corporate crime, Corporate Crime/Legal Action, Corporate/Industrial News, crime, Crime/Legal Action, Factiva Filters, Financial Crime, Financial Services, financial vehicles, Fraud, funds, game stores, GameStop, general news, GME, government policy, Hedge Funds, hobby, Hobby/Toy/Game Stores, industrial news, investing, Investing/Securities, legal action, Legal Services, mergers, North America, Ownership Changes, political, Political/General News, regulation, Regulation/Government Policy, Retail, Retail/Wholesale, securities, Securities Fraud, shareholdings, Specialty Retailing, SYND, toy, trusts, Trusts/Funds/Financial Vehicles, United States, wholesale, WSJ-PRO-WSJ.com},
}

@article{gwiazdzinski_psychological_2023,
	title = {Psychological interventions countering misinformation in social media: {A} scoping review},
	volume = {13},
	issn = {1664-0640},
	shorttitle = {Psychological interventions countering misinformation in social media},
	url = {https://www.frontiersin.org/journals/psychiatry/articles/10.3389/fpsyt.2022.974782/full},
	doi = {10.3389/fpsyt.2022.974782},
	abstract = {{\textless}sec{\textgreater}{\textless}title{\textgreater}Introduction{\textless}/title{\textgreater}{\textless}p{\textgreater}The rise of social media users and the explosive growth in misinformation shared across social media platforms have become a serious threat to democratic discourse and public health. The mentioned implications have increased the demand for misinformation detection and intervention. To contribute to this challenge, we are presenting a systematic scoping review of psychological interventions countering misinformation in social media. The review was conducted to (i) identify and map evidence on psychological interventions countering misinformation, (ii) compare the viability of the interventions on social media, and (iii) provide guidelines for the development of effective interventions.{\textless}/p{\textgreater}{\textless}/sec{\textgreater}{\textless}sec{\textgreater}{\textless}title{\textgreater}Methods{\textless}/title{\textgreater}{\textless}p{\textgreater}A systematic search in three bibliographic databases (PubMed, Embase, and Scopus) and additional searches in Google Scholar and reference lists were conducted.{\textless}/p{\textgreater}{\textless}/sec{\textgreater}{\textless}sec{\textgreater}{\textless}title{\textgreater}Results{\textless}/title{\textgreater}{\textless}p{\textgreater}3,561 records were identified, 75 of which met the eligibility criteria for the inclusion in the final review. The psychological interventions identified during the review can be classified into three categories distinguished by Kozyreva et al.: Boosting, Technocognition, and Nudging, and then into 15 types within these. Most of the studied interventions were not implemented and tested in a real social media environment but under strictly controlled settings or online crowdsourcing platforms. The presented feasibility assessment of implementation insights expressed qualitatively and with numerical scoring could guide the development of future interventions that can be successfully implemented on social media platforms.{\textless}/p{\textgreater}{\textless}/sec{\textgreater}{\textless}sec{\textgreater}{\textless}title{\textgreater}Discussion{\textless}/title{\textgreater}{\textless}p{\textgreater}The review provides the basis for further research on psychological interventions counteracting misinformation. Future research on interventions should aim to combine effective Technocognition and Nudging in the user experience of online services.{\textless}/p{\textgreater}{\textless}/sec{\textgreater}{\textless}sec{\textgreater}{\textless}title{\textgreater}Systematic review registration{\textless}/title{\textgreater}{\textless}p{\textgreater}[{\textless}ext-link ext-link-type="uri" xlink:href="https://figshare.com/" xmlns:xlink="http://www.w3.org/1999/xlink"{\textgreater}https://figshare.com/{\textless}/ext-link{\textgreater}], identifier [{\textless}ext-link ext-link-type="uri" xlink:href="https://doi.org/10.6084/m9.figshare.14649432.v2" xmlns:xlink="http://www.w3.org/1999/xlink"{\textgreater}https://doi.org/10.6084/m9.figshare.14649432.v2{\textless}/ext-link{\textgreater}].{\textless}/p{\textgreater}{\textless}/sec{\textgreater}},
	language = {English},
	urldate = {2024-11-23},
	journal = {Frontiers in Psychiatry},
	author = {Gwiaździński, Paweł and Gundersen, Aleksander B. and Piksa, Michal and Krysińska, Izabela and Kunst, Jonas R. and Noworyta, Karolina and Olejniuk, Agata and Morzy, Mikołaj and Rygula, Rafal and Wójtowicz, Tomi and Piasecki, Jan},
	month = jan,
	year = {2023},
	note = {Publisher: Frontiers},
	keywords = {facebook, misinformation, psychological interventions, Reddit, Scoping review, Social Media, Systematic review, Twitter},
	file = {Full Text PDF:files/29/Gwiaździński et al. - 2023 - Psychological interventions countering misinformat.pdf:application/pdf},
}

@article{britt_reasoned_2019,
	title = {A {Reasoned} {Approach} to {Dealing} {With} {Fake} {News}},
	volume = {6},
	issn = {2372-7322},
	url = {https://doi.org/10.1177/2372732218814855},
	doi = {10.1177/2372732218814855},
	abstract = {We now have almost no filters on information that we can access, and this requires a much more vigilant, knowledgeable reader. Learning false information from the web can have dire consequences for personal, social, and personal decision making. Given how our memory works and our biases in selecting and interpreting information, now more than ever we must control our own cognitive and affective processing. As examples: Simply repeating information can increase confidence in its perceived truth; initial incorrect information remains available and can continue to have an effect despite learning the corrected information; and we are more likely to accept information that is consistent with our beliefs. Information evaluation requires readers (a) to set and monitor their goals of accuracy, coherence, and completeness; (b) to employ strategies to achieve these goals; and (c) to value this time- and effort-consuming systematic evaluation. Several recommendations support a reasoned approach to fake news and manipulation.},
	language = {en},
	number = {1},
	urldate = {2024-11-23},
	journal = {Policy Insights from the Behavioral and Brain Sciences},
	author = {Britt, M. Anne and Rouet, Jean-François and Blaum, Dylan and Millis, Keith},
	month = mar,
	year = {2019},
	note = {Publisher: SAGE Publications},
	pages = {94--101},
}

@article{mazzeo_investigating_2022,
	title = {Investigating {Fake} and {Reliable} {News} {Sources} {Using} {Complex} {Networks} {Analysis}},
	volume = {10},
	issn = {2296-424X},
	url = {https://www.frontiersin.org/journals/physics/articles/10.3389/fphy.2022.886544/full},
	doi = {10.3389/fphy.2022.886544},
	abstract = {The rise of disinformation in the last years has shed light on the presence of bad actors that produce and spread misleading content every day. Therefore, looking at the characteristics of these actors has become crucial for gaining better knowledge of the phenomenon of disinformation to fight it. This study seeks to understand how these actors, meant here as unreliable news websites, differ from reliable ones. With this aim, we investigated some well-known fake and reliable news sources and their relationships, using a network growth model based on the overlap of their audience. Then, we peered into the news sites’ sub-networks and their structure, finding that unreliable news sources’ sub-networks are overall disassortative and have a low–medium clustering coefficient, indicative of a higher fragmentation. The k-core decomposition allowed us to find the coreness value for each node in the network, identifying the most connectedness site communities and revealing the structural organization of the network, where the unreliable websites tend to populate the inner shells. By analyzing WHOIS information, it also emerged that unreliable websites generally have a newer registration date and shorter-term registrations compared to reliable websites. The results on the political leaning of the news sources show extremist news sources of any political leaning are generally mostly responsible for producing and spreading disinformation.},
	language = {English},
	urldate = {2024-11-23},
	journal = {Frontiers in Physics},
	author = {Mazzeo, Valeria and Rapisarda, Andrea},
	month = jun,
	year = {2022},
	note = {Publisher: Frontiers},
	keywords = {audience overlap, complex networks, disinformation, fake news, SEO (search engine optimisation)},
	file = {Full Text PDF:files/32/Mazzeo y Rapisarda - 2022 - Investigating Fake and Reliable News Sources Using.pdf:application/pdf},
}

@misc{noauthor_2022_2024,
	title = {The 2022 {Code} of {Practice} on {Disinformation} {\textbar} {Shaping} {Europe}’s digital future},
	url = {https://digital-strategy.ec.europa.eu/en/policies/code-practice-disinformation},
	language = {en},
	urldate = {2024-11-23},
	month = oct,
	year = {2024},
}

@article{garimella_how_2024,
	title = {How prevalent is {AI} misinformation? {What} our studies in {India} show so far},
	volume = {630},
	copyright = {2024 Springer Nature Limited},
	shorttitle = {How prevalent is {AI} misinformation?},
	url = {https://www.nature.com/articles/d41586-024-01588-2},
	doi = {10.1038/d41586-024-01588-2},
	abstract = {A sample of roughly two million WhatsApp messages highlights urgent concerns about the spread and prevalence of AI-generated political content.},
	language = {en},
	number = {8015},
	urldate = {2024-11-23},
	journal = {Nature},
	author = {Garimella, Kiran and Chauchard, Simon},
	month = jun,
	year = {2024},
	note = {Bandiera\_abtest: a
Cg\_type: Comment
Publisher: Nature Publishing Group
Subject\_term: Policy, Politics, Society},
	keywords = {Policy, Politics, Society},
	pages = {32--34},
	file = {Full Text PDF:files/35/Garimella y Chauchard - 2024 - How prevalent is AI misinformation What our studi.pdf:application/pdf},
}

@misc{noauthor_gifct_nodate,
	title = {{GIFCT} about},
	url = {https://gifct.org/about/},
	language = {en-GB},
	urldate = {2024-11-23},
	journal = {GIFCT},
}

@misc{noauthor_disinformation_nodate,
	title = {Disinformation and public health},
	url = {https://www.who.int/news-room/questions-and-answers/item/disinformation-and-public-health},
	abstract = {This WHO questions and answers page looks at how health-related disinformation has emerged as a threat to public health and safety. It explains, in a general way, how Member States and individuals can help reduce the risks of information manipulation to themselves and their communities.},
	language = {en},
	urldate = {2024-11-23},
}

@misc{nations_united_nodate,
	title = {United {Nations} {Countering} {Disinformation}},
	url = {https://www.un.org/en/countering-disinformation},
	abstract = {While misinformation refers to the accidental spread of inaccurate information, disinformation is not only inaccurate, but intends to deceive and is spread in order to do serious harm.},
	language = {en},
	urldate = {2024-11-23},
	journal = {United Nations},
	author = {Nations, United},
	note = {Publisher: United Nations},
}

@misc{noauthor_journalism_nodate,
	title = {Journalism, '{Fake} {News}' and {Disinformation}: {A} {Handbook} for {Journalism} {Education} and {Training}},
	url = {https://webarchive.unesco.org/web/20230926213448/https://en.unesco.org/fightfakenews},
	urldate = {2024-11-23},
}

@article{safieddine_corporate_2016,
	title = {Corporate {Responsibility} in {Combating} {Online} {Misinformation}},
	volume = {7},
	issn = {2156-5570},
	url = {https://thesai.org/Publications/ViewPaper?Volume=7&Issue=2&Code=IJACSA&SerialNo=17},
	doi = {10.14569/IJACSA.2016.070217},
	abstract = {In the age of mass information and misinformation, the corporate duty of developers of browsers, social media, and search engines are falling short of the minimum standards of responsibility. The tools and technologies are already available to combat misinformation online but the desire to integrate these tools has not taken enough priority to warrant action. This paper presents an effective and practical method based on technologies already available that could be used for browsers and social media websites that would help combat misinformation presented in the form of photo evidence, video evidence, or textual evidence the authors have termed as the “Right-click Authenticate” every browser and social media website should have.},
	language = {en},
	number = {2},
	urldate = {2024-11-23},
	journal = {International Journal of Advanced Computer Science and Applications (IJACSA)},
	author = {Safieddine, Fadi and Masri, Wassim and Pourghomi, Pardis},
	month = jan,
	year = {2016},
	note = {Number: 2
Publisher: The Science and Information (SAI) Organization Limited},
	file = {Full Text PDF:files/41/Safieddine et al. - 2016 - Corporate Responsibility in Combating Online Misin.pdf:application/pdf},
}

@misc{noauthor_politifact_nodate,
	title = {Politifact {Fact} {Check} {Dataset}},
	url = {https://www.kaggle.com/datasets/rmisra/politifact-fact-check-dataset},
	abstract = {High-quality dataset with 21k fact check statements between 2008 to 2022},
	language = {en},
	urldate = {2024-11-24},
	file = {Snapshot:files/43/politifact-fact-check-dataset.html:text/html},
}

@book{rid_active_nodate,
	title = {Active {Measures}:  {The} {Secret} {History} of  {Disinformation} and  {Political} {Warfare}},
	isbn = {978-1-78816-074-2},
	language = {English},
	author = {Rid, Thomas},
}

@article{bahad_fake_2019,
	series = {2nd {International} {Conference} on {Recent} {Trends} in {Advanced} {Computing} {ICRTAC} -{DISRUP} - {TIV} {INNOVATION} , 2019 {November} 11-12, 2019},
	title = {Fake {News} {Detection} using {Bi}-directional {LSTM}-{Recurrent} {Neural} {Network}},
	volume = {165},
	issn = {1877-0509},
	url = {https://www.sciencedirect.com/science/article/pii/S1877050920300806},
	doi = {10.1016/j.procs.2020.01.072},
	abstract = {Media plays a vital role in the public dissemination of information about events. The rapid development of the Internet allows a quick spread of information through social networks or websites. Without the concern about the credibility of the information, the unverified or fake news is spread in social networks and reach thousands of users. Fake news is typically generated for commercial and political interests to mislead and attract readers. The spread of fake news has raised a big challenge to society. Automatic credibility analysis of news articles is a current research interest. Deep learning models are widely used for linguistic modeling. Typical deep learning models such as Convolutional Neural Networks (CNN) and Recurrent Neural Networks (RNN) can detect complex patterns in textual data. Long Short-Term Memory (LSTM) is a tree-structured recurrent neural network used to analyze variable-length sequential data. Bi-directional LSTM allows looking at particular sequence both from front-to-back as well as from back-to-front. The paper presents a fake news detection model based on Bi-directional LSTM-recurrent neural network. Two publicly available unstructured news articles datasets are used to assess the performance of the model. The result shows the superiority in terms of accuracy of Bi-directional LSTM model over other methods namely CNN, vanilla RNN and unidirectional LSTM for fake news detection.},
	urldate = {2024-11-24},
	journal = {Procedia Computer Science},
	author = {Bahad, Pritika and Saxena, Preeti and Kamal, Raj},
	month = jan,
	year = {2019},
	keywords = {Bi-directional LSTM, Convolutional Neural Network, Deep learning, Long Short-Term Memory, Recurrent Neural Network},
	pages = {74--82},
	file = {ScienceDirect Snapshot:files/46/S1877050920300806.html:text/html},
}

@misc{wang_liar_2017,
	title = {"{Liar}, {Liar} {Pants} on {Fire}": {A} {New} {Benchmark} {Dataset} for {Fake} {News} {Detection}},
	shorttitle = {"{Liar}, {Liar} {Pants} on {Fire}"},
	url = {http://arxiv.org/abs/1705.00648},
	doi = {10.48550/arXiv.1705.00648},
	abstract = {Automatic fake news detection is a challenging problem in deception detection, and it has tremendous real-world political and social impacts. However, statistical approaches to combating fake news has been dramatically limited by the lack of labeled benchmark datasets. In this paper, we present liar: a new, publicly available dataset for fake news detection. We collected a decade-long, 12.8K manually labeled short statements in various contexts from PolitiFact.com, which provides detailed analysis report and links to source documents for each case. This dataset can be used for fact-checking research as well. Notably, this new dataset is an order of magnitude larger than previously largest public fake news datasets of similar type. Empirically, we investigate automatic fake news detection based on surface-level linguistic patterns. We have designed a novel, hybrid convolutional neural network to integrate meta-data with text. We show that this hybrid approach can improve a text-only deep learning model.},
	urldate = {2024-11-24},
	publisher = {arXiv},
	author = {Wang, William Yang},
	month = may,
	year = {2017},
	note = {arXiv:1705.00648},
	keywords = {Computer Science - Computation and Language, Computer Science - Computers and Society},
	file = {Preprint PDF:files/48/Wang - 2017 - Liar, Liar Pants on Fire A New Benchmark Datase.pdf:application/pdf;Snapshot:files/49/1705.html:text/html},
}

@misc{shu_fakenewsnet_2019,
	title = {{FakeNewsNet}: {A} {Data} {Repository} with {News} {Content}, {Social} {Context} and {Spatialtemporal} {Information} for {Studying} {Fake} {News} on {Social} {Media}},
	shorttitle = {{FakeNewsNet}},
	url = {http://arxiv.org/abs/1809.01286},
	doi = {10.48550/arXiv.1809.01286},
	abstract = {Social media has become a popular means for people to consume news. Meanwhile, it also enables the wide dissemination of fake news, i.e., news with intentionally false information, which brings significant negative effects to the society. Thus, fake news detection is attracting increasing attention. However, fake news detection is a non-trivial task, which requires multi-source information such as news content, social context, and dynamic information. First, fake news is written to fool people, which makes it difficult to detect fake news simply based on news contents. In addition to news contents, we need to explore social contexts such as user engagements and social behaviors. For example, a credible user's comment that "this is a fake news" is a strong signal for detecting fake news. Second, dynamic information such as how fake news and true news propagate and how users' opinions toward news pieces are very important for extracting useful patterns for (early) fake news detection and intervention. Thus, comprehensive datasets which contain news content, social context, and dynamic information could facilitate fake news propagation, detection, and mitigation; while to the best of our knowledge, existing datasets only contains one or two aspects. Therefore, in this paper, to facilitate fake news related researches, we provide a fake news data repository FakeNewsNet, which contains two comprehensive datasets that includes news content, social context, and dynamic information. We present a comprehensive description of datasets collection, demonstrate an exploratory analysis of this data repository from different perspectives, and discuss the benefits of FakeNewsNet for potential applications on fake news study on social media.},
	urldate = {2024-11-24},
	publisher = {arXiv},
	author = {Shu, Kai and Mahudeswaran, Deepak and Wang, Suhang and Lee, Dongwon and Liu, Huan},
	month = mar,
	year = {2019},
	note = {arXiv:1809.01286},
	keywords = {Computer Science - Social and Information Networks},
	file = {Preprint PDF:files/51/Shu et al. - 2019 - FakeNewsNet A Data Repository with News Content, .pdf:application/pdf;Snapshot:files/52/1809.html:text/html},
}

@article{grinberg_fake_2019,
	title = {Fake news on {Twitter} during the 2016 {U}.{S}. presidential election},
	volume = {363},
	url = {https://www.science.org/doi/10.1126/science.aau2706},
	doi = {10.1126/science.aau2706},
	abstract = {The spread of fake news on social media became a public concern in the United States after the 2016 presidential election. We examined exposure to and sharing of fake news by registered voters on Twitter and found that engagement with fake news sources was extremely concentrated. Only 1\% of individuals accounted for 80\% of fake news source exposures, and 0.1\% accounted for nearly 80\% of fake news sources shared. Individuals most likely to engage with fake news sources were conservative leaning, older, and highly engaged with political news. A cluster of fake news sources shared overlapping audiences on the extreme right, but for people across the political spectrum, most political news exposure still came from mainstream media outlets.},
	number = {6425},
	urldate = {2024-11-24},
	journal = {Science},
	author = {Grinberg, Nir and Joseph, Kenneth and Friedland, Lisa and Swire-Thompson, Briony and Lazer, David},
	month = jan,
	year = {2019},
	note = {Publisher: American Association for the Advancement of Science},
	pages = {374--378},
}

@article{bessi_social_2016,
	title = {Social bots distort the 2016 {U}.{S}. {Presidential} election online discussion},
	copyright = {Copyright (c)},
	issn = {1396-0466},
	url = {https://firstmonday.org/ojs/index.php/fm/article/view/7090},
	doi = {10.5210/fm.v21i11.7090},
	abstract = {Social media have been extensively praised for increasing democratic discussion on social issues related to policy and politics. However, what happens when this powerful communication tools are exploited to manipulate online discussion, to change the public perception of political entities, or even to try affecting the outcome of political elections? In this study we investigated how the presence of social media bots, algorithmically driven entities that on the surface appear as legitimate users, affect political discussion around the 2016 U.S. Presidential election. By leveraging state-of-the-art social bot detection algorithms, we uncovered a large fraction of user population that may not be human, accounting for a significant portion of generated content (about one-fifth of the entire conversation). We inferred political partisanships from hashtag adoption, for both humans and bots, and studied spatio-temporal communication, political support dynamics, and influence mechanisms by discovering the level of network embeddedness of the bots. Our findings suggest that the presence of social media bots can indeed negatively affect democratic political discussion rather than improving it, which in turn can potentially alter public opinion and endanger the integrity of the Presidential election.},
	language = {en},
	urldate = {2024-11-24},
	journal = {First Monday},
	author = {Bessi, Alessandro and Ferrara, Emilio},
	month = nov,
	year = {2016},
}

@article{pennycook_fighting_2019,
	title = {Fighting misinformation on social media using crowdsourced judgments of news source quality},
	volume = {116},
	url = {https://www.pnas.org/doi/full/10.1073/pnas.1806781116},
	doi = {10.1073/pnas.1806781116},
	abstract = {Reducing the spread of misinformation, especially on social media, is a major challenge. We investigate one potential approach: having social media platform algorithms preferentially display content from news sources that users rate as trustworthy. To do so, we ask whether crowdsourced trust ratings can effectively differentiate more versus less reliable sources. We ran two preregistered experiments (n = 1,010 from Mechanical Turk and n = 970 from Lucid) where individuals rated familiarity with, and trust in, 60 news sources from three categories: (i) mainstream media outlets, (ii) hyperpartisan websites, and (iii) websites that produce blatantly false content (“fake news”). Despite substantial partisan differences, we find that laypeople across the political spectrum rated mainstream sources as far more trustworthy than either hyperpartisan or fake news sources. Although this difference was larger for Democrats than Republicans—mostly due to distrust of mainstream sources by Republicans—every mainstream source (with one exception) was rated as more trustworthy than every hyperpartisan or fake news source across both studies when equally weighting ratings of Democrats and Republicans. Furthermore, politically balanced layperson ratings were strongly correlated (r = 0.90) with ratings provided by professional fact-checkers. We also found that, particularly among liberals, individuals higher in cognitive reflection were better able to discern between low- and high-quality sources. Finally, we found that excluding ratings from participants who were not familiar with a given news source dramatically reduced the effectiveness of the crowd. Our findings indicate that having algorithms up-rank content from trusted media outlets may be a promising approach for fighting the spread of misinformation on social media.},
	number = {7},
	urldate = {2024-11-24},
	journal = {Proceedings of the National Academy of Sciences},
	author = {Pennycook, Gordon and Rand, David G.},
	month = feb,
	year = {2019},
	note = {Publisher: Proceedings of the National Academy of Sciences},
	pages = {2521--2526},
	file = {Full Text PDF:files/56/Pennycook y Rand - 2019 - Fighting misinformation on social media using crow.pdf:application/pdf},
}

@article{islam_deep_2020,
	title = {Deep learning for misinformation detection on online social networks: a survey and new perspectives},
	volume = {10},
	issn = {1869-5469},
	shorttitle = {Deep learning for misinformation detection on online social networks},
	url = {https://doi.org/10.1007/s13278-020-00696-x},
	doi = {10.1007/s13278-020-00696-x},
	abstract = {Recently, the use of social networks such as Facebook, Twitter, and Sina Weibo has become an inseparable part of our daily lives. It is considered as a convenient platform for users to share personal messages, pictures, and videos. However, while people enjoy social networks, many deceptive activities such as fake news or rumors can mislead users into believing misinformation. Besides, spreading the massive amount of misinformation in social networks has become a global risk. Therefore, misinformation detection (MID) in social networks has gained a great deal of attention and is considered an emerging area of research interest. We find that several studies related to MID have been studied to new research problems and techniques. While important, however, the automated detection of misinformation is difficult to accomplish as it requires the advanced model to understand how related or unrelated the reported information is when compared to real information. The existing studies have mainly focused on three broad categories of misinformation: false information, fake news, and rumor detection. Therefore, related to the previous issues, we present a comprehensive survey of automated misinformation detection on (i) false information, (ii) rumors, (iii) spam, (iv) fake news, and (v) disinformation. We provide a state-of-the-art review on MID where deep learning (DL) is used to automatically process data and create patterns to make decisions not only to extract global features but also to achieve better results. We further show that DL is an effective and scalable technique for the state-of-the-art MID. Finally, we suggest several open issues that currently limit real-world implementation and point to future directions along this dimension.},
	language = {en},
	number = {1},
	urldate = {2024-11-24},
	journal = {Social Network Analysis and Mining},
	author = {Islam, Md Rafiqul and Liu, Shaowu and Wang, Xianzhi and Xu, Guandong},
	month = sep,
	year = {2020},
	keywords = {Artificial Intelligence, Decision making, Deep learning, Misinformation detection, Neural network, Online social networks},
	pages = {82},
	file = {Full Text PDF:files/58/Islam et al. - 2020 - Deep learning for misinformation detection on onli.pdf:application/pdf},
}

@misc{micallef_role_2020,
	title = {The {Role} of the {Crowd} in {Countering} {Misinformation}: {A} {Case} {Study} of the {COVID}-19 {Infodemic}},
	shorttitle = {The {Role} of the {Crowd} in {Countering} {Misinformation}},
	url = {http://arxiv.org/abs/2011.05773},
	doi = {10.48550/arXiv.2011.05773},
	abstract = {Fact checking by professionals is viewed as a vital defense in the fight against misinformation.While fact checking is important and its impact has been significant, fact checks could have limited visibility and may not reach the intended audience, such as those deeply embedded in polarized communities. Concerned citizens (i.e., the crowd), who are users of the platforms where misinformation appears, can play a crucial role in disseminating fact-checking information and in countering the spread of misinformation. To explore if this is the case, we conduct a data-driven study of misinformation on the Twitter platform, focusing on tweets related to the COVID-19 pandemic, analyzing the spread of misinformation, professional fact checks, and the crowd response to popular misleading claims about COVID-19. In this work, we curate a dataset of false claims and statements that seek to challenge or refute them. We train a classifier to create a novel dataset of 155,468 COVID-19-related tweets, containing 33,237 false claims and 33,413 refuting arguments.Our findings show that professional fact-checking tweets have limited volume and reach. In contrast, we observe that the surge in misinformation tweets results in a quick response and a corresponding increase in tweets that refute such misinformation. More importantly, we find contrasting differences in the way the crowd refutes tweets, some tweets appear to be opinions, while others contain concrete evidence, such as a link to a reputed source. Our work provides insights into how misinformation is organically countered in social platforms by some of their users and the role they play in amplifying professional fact checks.These insights could lead to development of tools and mechanisms that can empower concerned citizens in combating misinformation. The code and data can be found in http://claws.cc.gatech.edu/covid\_counter\_misinformation.html.},
	urldate = {2024-11-24},
	publisher = {arXiv},
	author = {Micallef, Nicholas and He, Bing and Kumar, Srijan and Ahamad, Mustaque and Memon, Nasir},
	month = nov,
	year = {2020},
	note = {arXiv:2011.05773},
	keywords = {Computer Science - Computation and Language, Computer Science - Computers and Society, Computer Science - Social and Information Networks},
	file = {Preprint PDF:files/60/Micallef et al. - 2020 - The Role of the Crowd in Countering Misinformation.pdf:application/pdf;Snapshot:files/61/2011.html:text/html},
}

@article{kherwa_topic_2018,
	title = {Topic {Modeling}: {A} {Comprehensive} {Review}},
	volume = {7},
	shorttitle = {Topic {Modeling}},
	doi = {10.4108/eai.13-7-2018.159623},
	abstract = {Topic modelling is the new revolution in text mining. It is a statistical technique for revealing the underlying semantic structure in large collection of documents. After analysing approximately 300 research articles on topic modeling, a comprehensive survey on topic modelling has been presented in this paper. It includes classification hierarchy, Topic modelling methods, Posterior Inference techniques, different evolution models of latent Dirichlet allocation (LDA) and itsapplications in different areas of technology including Scientific Literature, Bioinformatics, Software Engineering and analysing social network is presented. Quantitative evaluation of topic modeling techniques is also presented in detail for better understanding the concept of topic modeling. At the end paper is concluded with detailed discussion on challengesof topic modelling, which will definitely give researchers an insight for good research.},
	journal = {ICST Transactions on Scalable Information Systems},
	author = {Kherwa, Pooja and Bansal, Poonam},
	month = jul,
	year = {2018},
	pages = {159623},
	file = {Full Text PDF:files/63/Kherwa y Bansal - 2018 - Topic Modeling A Comprehensive Review.pdf:application/pdf},
}

@article{vayansky_review_2020,
	title = {A review of topic modeling methods},
	volume = {94},
	issn = {0306-4379},
	url = {https://www.sciencedirect.com/science/article/pii/S0306437920300703},
	doi = {10.1016/j.is.2020.101582},
	abstract = {Topic modeling is a popular analytical tool for evaluating data. Numerous methods of topic modeling have been developed which consider many kinds of relationships and restrictions within datasets; however, these methods are not frequently employed. Instead many researchers gravitate to Latent Dirichlet Analysis, which although flexible and adaptive, is not always suited for modeling more complex data relationships. We present different topic modeling approaches capable of dealing with correlation between topics, the changes of topics over time, as well as the ability to handle short texts such as encountered in social media or sparse text data. We also briefly review the algorithms which are used to optimize and infer parameters in topic modeling, which is essential to producing meaningful results regardless of method. We believe this review will encourage more diversity when performing topic modeling and help determine what topic modeling method best suits the user needs.},
	urldate = {2024-11-24},
	journal = {Information Systems},
	author = {Vayansky, Ike and Kumar, Sathish A. P.},
	month = dec,
	year = {2020},
	keywords = {Inference algorithms, Probabilistic Bayesian networks, Social Media analysis, Temporal analysis, Text analysis, Topic correlation, Topic modeling},
	pages = {101582},
	file = {ScienceDirect Snapshot:files/66/S0306437920300703.html:text/html},
}

@misc{noauthor_what_2024,
	title = {What is topic modeling? {\textbar} {IBM}},
	shorttitle = {What is topic modeling?},
	url = {https://www.ibm.com/topics/topic-modeling},
	abstract = {Topic models are an unsupervised NLP method for summarizing text data through word groups. They assist in text classification and information retrieval tasks.},
	language = {en},
	urldate = {2024-11-24},
	month = mar,
	year = {2024},
}

@misc{noauthor_what_2024-1,
	title = {What is {Latent} {Dirichlet} allocation {\textbar} {IBM}},
	url = {https://www.ibm.com/topics/latent-dirichlet-allocation},
	abstract = {Latent Dirichlet allocation is a topic modeling technique for uncovering the central topics and their distributions across a set of documents.},
	language = {en},
	urldate = {2024-11-24},
	month = apr,
	year = {2024},
	file = {Snapshot:files/69/latent-dirichlet-allocation.html:text/html},
}

@article{blei_latent_nodate,
	title = {Latent {Dirichlet} {Allocation}},
	url = {https://www.jmlr.org/papers/volume3/blei03a/blei03a.pdf},
	abstract = {We describe latent Dirichlet allocation (LDA), a generative probabilistic model for collections of discrete data such as text corpora. LDA is a three-level hierarchical Bayesian model, in which each item of a collection is modeled as a ﬁnite mixture over an underlying set of topics. Each topic is, in turn, modeled as an inﬁnite mixture over an underlying set of topic probabilities. In the context of text modeling, the topic probabilities provide an explicit representation of a document. We present efﬁcient approximate inference techniques based on variational methods and an EM algorithm for empirical Bayes parameter estimation. We report results in document modeling, text classiﬁcation, and collaborative ﬁltering, comparing to a mixture of unigrams model and the probabilistic LSI model.},
	language = {en},
	author = {Blei, David M},
	file = {Blei - Latent Dirichlet Allocation.pdf:files/70/Blei - Latent Dirichlet Allocation.pdf:application/pdf},
}

@misc{noauthor_what_2021,
	title = {What {Is} {Monte} {Carlo} {Simulation}? {\textbar} {IBM}},
	shorttitle = {What {Is} {Monte} {Carlo} {Simulation}?},
	url = {https://www.ibm.com/topics/monte-carlo-simulation},
	abstract = {Monte Carlo Simulation is a type of computational algorithm that uses repeated random sampling to obtain the likelihood of a range of results of occurring.},
	language = {en},
	urldate = {2024-11-24},
	month = sep,
	year = {2021},
	file = {Snapshot:files/73/monte-carlo-simulation.html:text/html},
}

@misc{saxena_understanding_2024,
	title = {Understanding {Perplexity} in {Language} {Models}: {A} {Detailed} {Exploration}},
	shorttitle = {Understanding {Perplexity} in {Language} {Models}},
	url = {https://medium.com/@shubhamsd100/understanding-perplexity-in-language-models-a-detailed-exploration-2108b6ab85af},
	abstract = {Perplexity is a key metric in natural language processing (NLP) that measures the quality of a language model. It evaluates how well a…},
	language = {en},
	urldate = {2024-11-24},
	journal = {Medium},
	author = {Saxena, Shubham},
	month = jul,
	year = {2024},
	file = {Snapshot:files/75/understanding-perplexity-in-language-models-a-detailed-exploration-2108b6ab85af.html:text/html},
}

@book{menczer_first_2020,
	title = {A {First} {Course} in {Network} {Science}},
	isbn = {978-1-108-65394-7},
	abstract = {Networks are everywhere: networks of friends, transportation networks and the Web. Neurons in our brains and proteins within our bodies form networks that determine our intelligence and survival. This modern, accessible textbook introduces the basics of network science for a wide range of job sectors from management to marketing, from biology to engineering, and from neuroscience to the social sciences. Students will develop important, practical skills and learn to write code for using networks in their areas of interest - even as they are just learning to program with Python. Extensive sets of tutorials and homework problems provide plenty of hands-on practice and longer programming tutorials online further enhance students' programming skills. This intuitive and direct approach makes the book ideal for a first course, aimed at a wide audience without a strong background in mathematics or computing but with a desire to learn the fundamentals and applications of network science.},
	publisher = {Cambridge University Press},
	author = {Menczer, Filippo and Fortunato, Santo and Davis, Clayton A.},
	year = {2020},
	doi = {10.1017/9781108653947},
}

@misc{noauthor_euler_nodate,
	title = {Euler: {Koenigsberg} bridges {\textless} {Maze} texts},
	url = {https://www.cantab.net/users/michael.behrend/repubs/maze_maths/pages/euler.html},
	urldate = {2024-11-24},
	file = {Euler\: Koenigsberg bridges < Maze texts:files/80/euler.html:text/html},
}

@article{munoz_modeling_2024,
	title = {Modeling disinformation networks on {Twitter}: structure, behavior, and impact},
	volume = {9},
	copyright = {2024 The Author(s)},
	issn = {2364-8228},
	shorttitle = {Modeling disinformation networks on {Twitter}},
	url = {https://appliednetsci.springeropen.com/articles/10.1007/s41109-024-00610-w},
	doi = {10.1007/s41109-024-00610-w},
	abstract = {The influence and pervasiveness of misinformation on social media platforms such as Twitter have been well-documented in recent years. These platforms’ real-time, rapid-fire nature and the personalized, echo-chamber-like environments they foster, often inadvertently, assist in misinformation amplification. To better understand this situation and how to encourage safer and broader narratives, this paper presents a comparative study of the activity of 275 Twitter accounts tagged as disinformation sources and 275 accounts tagged as legitimate journalists over a 3.5-year period in the Spanish context. By employing various modeling techniques, we investigate the structural differences and behavioral patterns between the two groups. Our findings demonstrate that disinformation accounts exhibit a coordinated behavior, among other distinct characteristics, leading to more efficient (dis)information propagation. The implications of these findings for understanding the dynamics of disinformation networks and combating their impact are discussed.},
	language = {en},
	number = {1},
	urldate = {2024-11-25},
	journal = {Applied Network Science},
	author = {Muñoz, Pau and Díez, Fernando and Bellogín, Alejandro},
	month = dec,
	year = {2024},
	note = {Number: 1
Publisher: SpringerOpen},
	pages = {1--35},
	file = {Full Text PDF:files/82/Muñoz et al. - 2024 - Modeling disinformation networks on Twitter struc.pdf:application/pdf},
}

@article{lakzaei_disinformation_2024,
	title = {Disinformation detection using graph neural networks: a survey},
	volume = {57},
	issn = {1573-7462},
	shorttitle = {Disinformation detection using graph neural networks},
	url = {https://doi.org/10.1007/s10462-024-10702-9},
	doi = {10.1007/s10462-024-10702-9},
	abstract = {The creation and propagation of disinformation on social media is a growing concern. The widespread dissemination of disinformation can have destructive effects on people’s attitudes and behavior. So, it is essential to detect disinformation as soon as possible. Therefore, the interest in effective detection techniques has grown rapidly in recent years. Major social media and social networking sites are trying to develop robust strategies to detect disinformation and prevent its spread. Machine learning techniques and especially neural networks, have an essential role in this task. In this paper, we review different approaches for automatic disinformation detection, with a focus on methods that leverage graph neural networks (GNNs). GNNs are very suitable tools for detecting disinformation in social networks. Because on the one hand, graphs are the most comprehensive way to model social networks and on the other hand, GNNs are the best tool for processing graph data. We define different forms of disinformation, and examine the features used and the methods presented from different perspectives. We also discuss relevant research areas, open problems, and future research directions for disinformation detection in social media.},
	language = {en},
	number = {3},
	urldate = {2024-11-25},
	journal = {Artificial Intelligence Review},
	author = {Lakzaei, Batool and Haghir Chehreghani, Mostafa and Bagheri, Alireza},
	month = feb,
	year = {2024},
	keywords = {Artificial Intelligence, Disinformation, Graph neural networks, Social networks},
	pages = {52},
	file = {Full Text PDF:files/84/Lakzaei et al. - 2024 - Disinformation detection using graph neural networ.pdf:application/pdf},
}

@misc{paraschiv_unified_2021,
	title = {A {Unified} {Graph}-{Based} {Approach} to {Disinformation} {Detection} using {Contextual} and {Semantic} {Relations}},
	url = {http://arxiv.org/abs/2109.11781},
	doi = {10.48550/arXiv.2109.11781},
	abstract = {As recent events have demonstrated, disinformation spread through social networks can have dire political, economic and social consequences. Detecting disinformation must inevitably rely on the structure of the network, on users particularities and on event occurrence patterns. We present a graph data structure, which we denote as a meta-graph, that combines underlying users' relational event information, as well as semantic and topical modeling. We detail the construction of an example meta-graph using Twitter data covering the 2016 US election campaign and then compare the detection of disinformation at cascade level, using well-known graph neural network algorithms, to the same algorithms applied on the meta-graph nodes. The comparison shows a consistent 3\%-4\% improvement in accuracy when using the meta-graph, over all considered algorithms, compared to basic cascade classification, and a further 1\% increase when topic modeling and sentiment analysis are considered. We carry out the same experiment on two other datasets, HealthRelease and HealthStory, part of the FakeHealth dataset repository, with consistent results. Finally, we discuss further advantages of our approach, such as the ability to augment the graph structure using external data sources, the ease with which multiple meta-graphs can be combined as well as a comparison of our method to other graph-based disinformation detection frameworks.},
	urldate = {2024-11-25},
	publisher = {arXiv},
	author = {Paraschiv, Marius and Salamanos, Nikos and Iordanou, Costas and Laoutaris, Nikolaos and Sirivianos, Michael},
	month = sep,
	year = {2021},
	note = {arXiv:2109.11781},
	keywords = {Computer Science - Social and Information Networks},
	file = {Preprint PDF:files/86/Paraschiv et al. - 2021 - A Unified Graph-Based Approach to Disinformation D.pdf:application/pdf;Snapshot:files/87/2109.html:text/html},
}

@misc{smith_automatic_2021,
	title = {Automatic {Detection} of {Influential} {Actors} in {Disinformation} {Networks}},
	url = {http://arxiv.org/abs/2005.10879},
	doi = {10.48550/arXiv.2005.10879},
	abstract = {The weaponization of digital communications and social media to conduct disinformation campaigns at immense scale, speed, and reach presents new challenges to identify and counter hostile influence operations (IOs). This paper presents an end-to-end framework to automate detection of disinformation narratives, networks, and influential actors. The framework integrates natural language processing, machine learning, graph analytics, and a novel network causal inference approach to quantify the impact of individual actors in spreading IO narratives. We demonstrate its capability on real-world hostile IO campaigns with Twitter datasets collected during the 2017 French presidential elections, and known IO accounts disclosed by Twitter over a broad range of IO campaigns (May 2007 to February 2020), over 50,000 accounts, 17 countries, and different account types including both trolls and bots. Our system detects IO accounts with 96\% precision, 79\% recall, and 96\% area-under-the-PR-curve, maps out salient network communities, and discovers high-impact accounts that escape the lens of traditional impact statistics based on activity counts and network centrality. Results are corroborated with independent sources of known IO accounts from U.S. Congressional reports, investigative journalism, and IO datasets provided by Twitter.},
	urldate = {2024-11-25},
	publisher = {arXiv},
	author = {Smith, Steven T. and Kao, Edward K. and Mackin, Erika D. and Shah, Danelle C. and Simek, Olga and Rubin, Donald B.},
	month = jan,
	year = {2021},
	note = {arXiv:2005.10879},
	keywords = {Computer Science - Machine Learning, Computer Science - Social and Information Networks, Statistics - Applications, Statistics - Machine Learning},
	file = {Preprint PDF:files/89/Smith et al. - 2021 - Automatic Detection of Influential Actors in Disin.pdf:application/pdf;Snapshot:files/90/2005.html:text/html},
}

@misc{khan_behavioral_2023,
	title = {Behavioral {Forensics} in {Social} {Networks}: {Identifying} {Misinformation}, {Disinformation} and {Refutation} {Spreaders} {Using} {Machine} {Learning}},
	shorttitle = {Behavioral {Forensics} in {Social} {Networks}},
	url = {http://arxiv.org/abs/2305.00957},
	doi = {10.48550/arXiv.2305.00957},
	abstract = {With the ever-increasing spread of misinformation on online social networks, it has become very important to identify the spreaders of misinformation (unintentional), disinformation (intentional), and misinformation refutation. It can help in educating the first, stopping the second, and soliciting the help of the third category, respectively, in the overall effort to counter misinformation spread. Existing research to identify spreaders is limited to binary classification (true vs false information spreaders). However, people's intention (whether naive or malicious) behind sharing misinformation can only be understood after observing their behavior after exposure to both the misinformation and its refutation which the existing literature lacks to consider. In this paper, we propose a labeling mechanism to label people as one of the five defined categories based on the behavioral actions they exhibit when exposed to misinformation and its refutation. However, everyone does not show behavioral actions but is part of a network. Therefore, we use their network features, extracted through deep learning-based graph embedding models, to train a machine learning model for the prediction of the classes. We name our approach behavioral forensics since it is an evidence-based investigation of suspicious behavior which is spreading misinformation and disinformation in our case. After evaluating our proposed model on a real-world Twitter dataset, we achieved 77.45\% precision and 75.80\% recall in detecting the malicious actors, who shared the misinformation even after receiving its refutation. Such behavior shows intention, and hence these actors can rightfully be called agents of disinformation spread.},
	urldate = {2024-11-25},
	publisher = {arXiv},
	author = {Khan, Euna Mehnaz and Ram, Ayush and Rath, Bhavtosh and Vraga, Emily and Srivastava, Jaideep},
	month = may,
	year = {2023},
	note = {arXiv:2305.00957},
	keywords = {Computer Science - Social and Information Networks},
	file = {Preprint PDF:files/92/Khan et al. - 2023 - Behavioral Forensics in Social Networks Identifyi.pdf:application/pdf;Snapshot:files/93/2305.html:text/html},
}

@misc{noauthor_statistics_nodate,
	title = {Statistics},
	url = {https://www.itu.int:443/en/ITU-D/Statistics/pages/stat/default.aspx},
	language = {en-US},
	urldate = {2024-11-25},
	journal = {ITU},
}

@misc{noauthor_breaking_nodate,
	title = {Breaking {Down} {The} {Numbers}: {How} {Much} {Data} {Does} {The} {World} {Create} {Daily} in 2024? {\textbar} {Edge} {Delta}},
	shorttitle = {Breaking {Down} {The} {Numbers}},
	url = {https://edgedelta.com/company/blog/how-much-data-is-created-per-day},
	abstract = {Discover the daily data creation volume in 2024. Explore global insights on how much data is generated per day. Click to learn more!},
	language = {en},
	urldate = {2024-11-25},
}

@misc{noauthor_data_nodate,
	title = {Data growth worldwide 2010-2028},
	url = {https://www.statista.com/statistics/871513/worldwide-data-created/},
	abstract = {The total global volume of data is set to explode over the coming years, amounting to an expected 394 zettabytes by 2028, up from just two zettabytes in 2010.},
	language = {en},
	urldate = {2024-11-25},
	journal = {Statista},
}

@book{barabasi_network_2016,
	title = {Network {Science}},
	isbn = {978-1-107-07626-6},
	abstract = {Networks are everywhere, from the internet, to social networks, and the genetic networks that determine our biological existence. Illustrated throughout in full colour, this pioneering textbook, spanning a wide range of topics from physics to computer science, engineering, economics and the social sciences, introduces network science to an interdisciplinary audience. From the origins of the six degrees of separation to explaining why networks are robust to random failures, the author explores how viruses like Ebola and H1N1 spread, and why it is that our friends have more friends than we do. Using numerous real-world examples, this innovatively designed text includes clear delineation between undergraduate and graduate level material. The mathematical formulas and derivations are included within Advanced Topics sections, enabling use at a range of levels. Extensive online resources, including films and software for network analysis, make this a multifaceted companion for anyone with an interest in network science.},
	language = {en},
	publisher = {Cambridge University Press},
	author = {Barabási, Albert-László and PÃ3sfai, MÃ¡rton},
	month = jul,
	year = {2016},
	note = {Google-Books-ID: ZVHesgEACAAJ},
	keywords = {Computers / Information Technology, Computers / Networking / General, Computers / Programming / Algorithms, Science / Physics / General, Science / Physics / Mathematical \& Computational},
}

@book{noauthor_network_nodate,
	title = {Network {Science} by {Albert}-{László} {Barabási}},
	url = {http://networksciencebook.com/},
	abstract = {The power of network science, the beauty of network visualization.},
	urldate = {2024-11-25},
}

@article{wang_complex_2003,
	title = {Complex networks: {Small}-world, scale-free and beyond},
	volume = {3},
	shorttitle = {Complex networks},
	doi = {10.1109/MCAS.2003.1228503},
	abstract = {In the past few years, the discovery of small-world and scale-free properties of many natural and artificial complex networks has stimulated a great deal of interest in studying the underlying organizing principles of various complex networks, which has led to dramatic advances in this emerging and active field of research. The present article reviews some basic concepts, important progress, and significant results in the current studies of various complex networks, with emphasis on the relationship between the topology and the dynamics of such complex networks. Some fundamental properties and typical complex network models are described; and, as an example, epidemic dynamics are analyzed and discussed in some detail. Finally, the important issue of robustness versus fragility of dynamical synchronization in complex networks is introduced and discussed.},
	journal = {Circuits and Systems Magazine, IEEE},
	author = {Wang, Xiao and Chen, Guanrong},
	month = feb,
	year = {2003},
	pages = {6--20},
	file = {Full Text PDF:files/101/Wang y Chen - 2003 - Complex networks Small-world, scale-free and beyo.pdf:application/pdf},
}

@article{mata_complex_2020,
	title = {Complex {Networks}: a {Mini}-review},
	volume = {50},
	issn = {1678-4448},
	shorttitle = {Complex {Networks}},
	url = {https://doi.org/10.1007/s13538-020-00772-9},
	doi = {10.1007/s13538-020-00772-9},
	abstract = {Network analysis is a powerful tool that provides us a fruitful framework to describe phenomena related to social, technological, and many other real-world complex systems. In this paper, we present a brief review about complex networks including fundamental quantities, examples of network models, and the essential role of network topology in the investigation of dynamical processes as epidemics, rumor spreading, and synchronization. A quite of advances have been provided in this field, and many other authors also review the main contributions in this area over the years. However, we show an overview from a different perspective. Our aim is to provide basic information to a broad audience and more detailed references for those who would like to learn deeper the topic.},
	language = {en},
	number = {5},
	urldate = {2024-11-25},
	journal = {Brazilian Journal of Physics},
	author = {Mata, Angélica Sousa da},
	month = oct,
	year = {2020},
	keywords = {Centrality measures, Complex networks, Dynamical process, Models},
	pages = {658--672},
	file = {Full Text PDF:files/104/Mata - 2020 - Complex Networks a Mini-review.pdf:application/pdf},
}

@misc{noauthor_facts_nodate,
	title = {Facts and {Figures} 2023 - {Internet} use},
	url = {https://www.itu.int/itu-d/reports/statistics/2023/10/10/ff23-internet-use},
	abstract = {The number and percentage of Internet users worldwide.},
	language = {en},
	urldate = {2024-11-25},
	file = {Snapshot:files/106/ff23-internet-use.html:text/html},
}
